"""
Routes pour la gestion des t√¢ches
"""
from fastapi import APIRouter, HTTPException, Body, Query, Path
from typing import Dict, Any, List, Optional
import json
import os
import logging
import re
from openai import OpenAI
from services.supabase_service import supabase_service
from pydantic import BaseModel

# Configuration du logging
logger = logging.getLogger(__name__)

# Cr√©ation du router
router = APIRouter(tags=["tasks"])

# Mod√®les Pydantic pour la validation des donn√©es
class TaskBase(BaseModel):
    title: str
    deadline: Optional[str] = None
    category: Optional[str] = None
    priority: Optional[str] = "medium"
    completed: Optional[bool] = False

class TaskCreate(TaskBase):
    pass

class TaskUpdate(BaseModel):
    title: Optional[str] = None
    deadline: Optional[str] = None
    category: Optional[str] = None
    priority: Optional[str] = None
    completed: Optional[bool] = None

class Task(TaskBase):
    id: int
    
    class Config:
        orm_mode = True

# Mod√®le flexible pour les donn√©es de la DB (sans validation stricte)
class TaskDB(BaseModel):
    id: int
    title: Optional[str] = None
    text: Optional[str] = None
    theme: Optional[str] = None
    hashtags: Optional[List[str]] = None
    eisenhower: Optional[str] = None
    estimated_time: Optional[str] = None
    deadline: Optional[str] = None
    category: Optional[str] = None
    priority: Optional[str] = "medium"
    completed: Optional[bool] = False
    user_id: Optional[str] = None
    created_at: Optional[str] = None
    
    class Config:
        orm_mode = True

# Cat√©gories de t√¢ches
CATEGORIES = [
    "personnel", "professionnel", "sant√©", "finance", 
    "√©ducation", "loisirs", "famille", "autre",
    "Vid√©o", "Organisation", "Productivit√©", "Travailler",
    "Suivi personnel", "Automatisation", "Marketing", "Technique"
]

# API pour r√©cup√©rer les cat√©gories
@router.get("/categories", response_model=Dict[str, list])
async def get_categories():
    return {"categories": CATEGORIES}

# API pour r√©cup√©rer toutes les t√¢ches (route de test)
@router.get("/tasks-all")
async def get_all_tasks_test():
    try:
        logger.info("üîÑ Route test /tasks-all")
        tasks = await supabase_service.get_all_tasks()
        logger.info(f"‚úÖ R√©cup√©r√© {len(tasks)} t√¢ches")
        return {"tasks": tasks}
    except Exception as e:
        logger.error(f"‚ùå Erreur: {str(e)}")
        import traceback
        logger.error(f"‚ùå Traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Erreur interne: {str(e)}")

# API pour r√©cup√©rer toutes les t√¢ches
@router.get("/tasks")
async def get_all_tasks():
    logger.info("üî• === D√âBUT GET /api/tasks ===")
    try:
        logger.info("üîÑ Appel supabase_service.get_all_tasks()...")
        tasks = await supabase_service.get_all_tasks()
        logger.info(f"‚úÖ R√©cup√©r√© {len(tasks)} t√¢ches depuis Supabase")
        
        # Afficher un aper√ßu des t√¢ches
        for i, task in enumerate(tasks[:3]):  # Limiter √† 3 pour les logs
            logger.info(f"  üìã T√¢che {i+1}: ID={task.get('id')}, text='{task.get('text', '')[:50]}...'")
        
        logger.info("üîÑ Cr√©ation de la r√©ponse JSON...")
        response = {"tasks": tasks}
        logger.info(f"‚úÖ Response cr√©√©e avec {len(tasks)} t√¢ches")
        logger.info("üî• === FIN GET /api/tasks (SUCC√àS) ===")
        
        return response
    except Exception as e:
        logger.error(f"‚ùå === ERREUR GET /api/tasks ===")
        logger.error(f"‚ùå Erreur: {str(e)}")
        import traceback
        logger.error(f"‚ùå Traceback: {traceback.format_exc()}")
        logger.error(f"‚ùå === FIN GET /api/tasks (ERREUR) ===")
        raise HTTPException(status_code=500, detail=f"Erreur interne: {str(e)}")

# API pour cr√©er une nouvelle t√¢che
@router.post("/tasks", response_model=Dict[str, Task])
async def create_task(task: TaskCreate):
    try:
        # Convertir le mod√®le Pydantic en dictionnaire
        task_data = task.dict()
        
        # Cr√©er la t√¢che dans la base de donn√©es
        created_task = await supabase_service.create_task(task_data)
        
        if not created_task:
            raise HTTPException(status_code=500, detail="Erreur lors de la cr√©ation de la t√¢che")
        
        return {"task": created_task}
    except Exception as e:
        logger.error(f"Erreur lors de la cr√©ation de la t√¢che: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur interne: {str(e)}")

# API pour r√©cup√©rer une t√¢che par son ID
@router.get("/tasks/{task_id}", response_model=Dict[str, Task])
async def get_task(task_id: int = Path(..., title="ID de la t√¢che")):
    try:
        task = await supabase_service.get_task_by_id(task_id)
        
        if not task:
            raise HTTPException(status_code=404, detail=f"T√¢che avec ID {task_id} non trouv√©e")
        
        return {"task": task}
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur lors de la r√©cup√©ration de la t√¢che {task_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur interne: {str(e)}")

# API pour mettre √† jour une t√¢che (route de test)
@router.put("/tasks-update/{task_id}")
async def update_task_test(
    task_id: int,
    data: Dict[str, Any] = Body(...)
):
    logger.info(f"üîÑ === D√âBUT PUT /api/tasks-update/{task_id} ===")
    try:
        logger.info(f"üîÑ Donn√©es re√ßues: {data}")
        
        if not data:
            raise HTTPException(status_code=400, detail="Aucune donn√©e fournie")
        
        # Mettre √† jour la t√¢che
        logger.info(f"üîÑ Appel supabase_service.update_task_by_id({task_id}, {data})")
        updated_task = await supabase_service.update_task_by_id(task_id, data)
        logger.info(f"‚úÖ T√¢che mise √† jour: {updated_task}")
        
        if not updated_task:
            raise HTTPException(status_code=404, detail=f"T√¢che avec ID {task_id} non trouv√©e")
        
        logger.info(f"üî• === FIN PUT /api/tasks-update/{task_id} (SUCC√àS) ===")
        return {"task": updated_task}
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå === ERREUR PUT /api/tasks-update/{task_id} ===")
        logger.error(f"‚ùå Erreur: {str(e)}")
        import traceback
        logger.error(f"‚ùå Traceback: {traceback.format_exc()}")
        logger.error(f"‚ùå === FIN PUT /api/tasks-update/{task_id} (ERREUR) ===")
        raise HTTPException(status_code=500, detail=f"Erreur interne: {str(e)}")

# API pour mettre √† jour une t√¢che
@router.put("/tasks/{task_id}", response_model=Dict[str, Task])
async def update_task_by_id(
    updates: TaskUpdate,
    task_id: int = Path(..., title="ID de la t√¢che")
):
    logger.info(f"üîÑ === D√âBUT PUT /api/tasks/{task_id} ===")
    try:
        logger.info(f"üîÑ Donn√©es re√ßues: {updates}")
        
        # Convertir le mod√®le Pydantic en dictionnaire, en excluant les None
        update_data = {k: v for k, v in updates.dict().items() if v is not None}
        logger.info(f"üîÑ Donn√©es filtr√©es: {update_data}")
        
        if not update_data:
            raise HTTPException(status_code=400, detail="Aucune donn√©e fournie pour la mise √† jour")
        
        # Mettre √† jour la t√¢che
        logger.info(f"üîÑ Appel supabase_service.update_task_by_id({task_id}, {update_data})")
        updated_task = await supabase_service.update_task_by_id(task_id, update_data)
        logger.info(f"‚úÖ T√¢che mise √† jour: {updated_task}")
        
        if not updated_task:
            raise HTTPException(status_code=404, detail=f"T√¢che avec ID {task_id} non trouv√©e")
        
        logger.info(f"üî• === FIN PUT /api/tasks/{task_id} (SUCC√àS) ===")
        return {"task": updated_task}
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå === ERREUR PUT /api/tasks/{task_id} ===")
        logger.error(f"‚ùå Erreur: {str(e)}")
        import traceback
        logger.error(f"‚ùå Traceback: {traceback.format_exc()}")
        logger.error(f"‚ùå === FIN PUT /api/tasks/{task_id} (ERREUR) ===")
        raise HTTPException(status_code=500, detail=f"Erreur interne: {str(e)}")

# API pour supprimer une t√¢che
@router.delete("/tasks/{task_id}", response_model=Dict[str, bool])
async def delete_task_by_id(task_id: int = Path(..., title="ID de la t√¢che")):
    try:
        success = await supabase_service.delete_task_by_id(task_id)
        
        if not success:
            raise HTTPException(status_code=404, detail=f"T√¢che avec ID {task_id} non trouv√©e")
        
        return {"success": True}
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur lors de la suppression de la t√¢che {task_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur interne: {str(e)}")

# API pour g√©n√©rer des t√¢ches simples (fallback)
@router.post("/generate_tasks")
async def generate_simple_tasks(data: Dict[str, Any] = Body(...)):
    theme = data.get("theme", "")
    
    if not theme:
        raise HTTPException(status_code=400, detail="Aucun th√®me fourni")
    
    # G√©n√©rer des t√¢ches basiques
    tasks = []
    for i in range(5):
        tasks.append({
            "id": i + 1,
            "text": f"T√¢che {i+1} pour {theme}",
            "completed": False
        })
    
    return {"theme": theme, "tasks": tasks}

# API pour g√©n√©rer des t√¢ches avec OpenAI
@router.post("/generate")
async def generate_tasks(data: Dict[str, Any] = Body(...)):
    logger.info("üöÄ === D√âBUT POST /api/generate ===")
    try:
        if not data:
            raise HTTPException(status_code=400, detail="Donn√©es invalides")
        
        theme = data.get("theme", "").strip()
        logger.info(f"üéØ Th√®me re√ßu: '{theme}'")
        if not theme:
            raise HTTPException(status_code=400, detail="Veuillez sp√©cifier un th√®me")
        
        is_smart_objective = data.get("is_smart_objective", False)
        logger.info(f"üß† Mode SMART: {is_smart_objective}")
        
        # D√©tection multi-t√¢ches (virgule, point-virgule, retour √† la ligne)
        split_themes = re.split(r"[,;\n]+", theme)
        split_themes = [t.strip() for t in split_themes if t.strip()]
        is_multi = len(split_themes) > 1
        logger.info(f"üìù Multi-t√¢ches d√©tect√©: {is_multi} ({len(split_themes)} th√®mes)")
        
        # V√©rifier si le th√®me existe d√©j√†
        existing_tasks = await supabase_service.get_tasks_by_theme(theme)
        logger.info(f"üîç T√¢ches existantes pour '{theme}': {len(existing_tasks)}")
        if existing_tasks and not is_smart_objective and not is_multi:
            logger.info("‚ôªÔ∏è Retour des t√¢ches existantes (pas de g√©n√©ration)")
            return {"theme": theme, "tasks": existing_tasks}
        
        client = OpenAI(
            api_key=os.environ.get("OPENAI_API_KEY"),
        )
        
        if is_smart_objective:
            # G√©n√©rer un objectif SMART et des t√¢ches associ√©es
            response = client.chat.completions.create(
                model=os.environ.get("MODEL_OPENAI"),
                messages=[
                    {"role": "system", "content": f"""Tu es un assistant sp√©cialis√© dans la transformation d'objectifs vagues en objectifs SMART.
                    
                    Pour l'objectif : "{theme}"
                    
                    1. Transforme-le en objectif SMART:
                       - Sp√©cifique: pr√©cis et concret
                       - Mesurable: avec des crit√®res quantifiables
                       - Atteignable: r√©aliste avec les moyens disponibles
                       - R√©aliste: adapt√© au contexte
                       - Temporel: avec une √©ch√©ance
                    
                    2. Propose 5 t√¢ches concr√®tes pour atteindre cet objectif.
                    
                    R√©ponds avec un objet JSON contenant:
                    {
                        "smart_objective": {
                            "title": "Titre reformul√© de l'objectif en 3/4 mots",
                            "specific": "Explication de l'aspect sp√©cifique",
                            "measurable": "Explication de l'aspect mesurable",
                            "achievable": "Explication de l'aspect atteignable",
                            "realistic": "Explication de l'aspect r√©aliste",
                            "time_bound": "√âch√©ance pr√©cise"
                        },
                        "tasks": [
                            {
                                "id": 1,
                                "text": "Description de la t√¢che en 3/4 mots",
                                "hashtags": ["cat√©gorie1", "cat√©gorie2"],
                                "eisenhower": "important_urgent" | "important_not_urgent" | "not_important_urgent" | "not_important_not_urgent",
                                "estimated_time": "45min",
                                "deadline": "YYYY-MM-DD"
                            },
                        ]
                    }
                    """}
                ],
                temperature=0.5,
            )
        elif is_multi:
            # G√©n√©ration multi-t√¢ches IA
            prompt = f"""
                        Tu es un assistant qui g√©n√®re une liste de t√¢ches d√©taill√©es √† partir d'une liste d'items. Pour chaque item ci-dessous, cr√©e une t√¢che claire et concise, avec :
                        - un titre court (max 3/4 caract√®res)
                        - une description d√©taill√©e
                        - un ou deux hashtags pertinents (ex: #productivit√©, #sant√©)
                        - une priorit√© selon la matrice d'Eisenhower (important_urgent, important_not_urgent, not_important_urgent, not_important_not_urgent)
                        - une estimation du temps (ex: 30min, 1h)
                        - une deadline logique (YYYY-MM-DD)

                        Retourne un tableau JSON de t√¢ches, chaque t√¢che au format :
                        {
                        "id": 1,
                        "title": "Titre court max 3/4 caract√®res",
                        "text": "Description court max 3/4 mots",
                        "hashtags": ["hashtag1", "hashtag2"],
                        "eisenhower": "important_urgent",
                        "estimated_time": "30min",
                        "deadline": "2024-06-01",
                        "completed": false
                        }

Liste d'items :
{split_themes}
"""
            response = client.chat.completions.create(
                model=os.environ.get("MODEL_OPENAI"),
                messages=[
                    {"role": "system", "content": prompt}
                ],
                temperature=0.5,
            )
            response_text = response.choices[0].message.content.strip()
            # Extraire le JSON
            json_match = re.search(r'\[.*\]', response_text, re.DOTALL)
            if json_match:
                response_text = json_match.group(0)
            try:
                tasks = json.loads(response_text)
                for t in tasks:
                    t["completed"] = t.get("completed", False)
                    if "theme" not in t:
                        t["theme"] = theme
                    if "user_id" not in t:
                        t["user_id"] = "test_user"
                for t in tasks:
                    await supabase_service.create_task(t)
                return {"theme": theme, "tasks": tasks}
            except json.JSONDecodeError as e:
                logger.error(f"Erreur lors du parsing JSON multi-t√¢ches: {str(e)}")
                raise HTTPException(status_code=500, detail="Erreur lors de la g√©n√©ration des t√¢ches multiples")
        else:
            # G√©n√©rer une t√¢che unique
            response = client.chat.completions.create(
                model=os.environ.get("MODEL_OPENAI"),
                messages=[
                    {"role": "system", "content": f"""Tu es un assistant qui g√©n√®re une t√¢che unique et d√©taill√©e avec un titre en 3/5 mots. 
                    Cr√©e une seule t√¢che pour le th√®me: {theme}.
                    
                    Pour cette t√¢che:
                    - Donne une description claire et pr√©cise
                    - Ajoute un ou deux hashtags pertinents (par exemple #productivit√©, #sport, #sant√©, #finance)
                    - D√©termine sa priorit√© selon la matrice d'Eisenhower (important_urgent, important_not_urgent, not_important_urgent, not_important_not_urgent)
                    - Estime le temps n√©cessaire (15min, 30min, 1h, etc.)
                    - Propose une deadline logique (YYYY-MM-DD)
                    
                    Retourne un objet JSON avec ces cl√©s:
                    - id (1)
                    - text (description de la t√¢che court max 3/4 mots)
                    - hashtags (liste de hashtags pertinents sans le symbole #)
                    - eisenhower (important_urgent, important_not_urgent, not_important_urgent, not_important_not_urgent)
                    - estimated_time (cha√Æne de caract√®res comme "30min" ou "2h")
                    - deadline (format YYYY-MM-DD)
                    - completed (toujours false)
                    """}
                ],
                temperature=0.5,
            )
        
        response_text = response.choices[0].message.content.strip()
        
        # Extraire le JSON des r√©ponses
        if is_smart_objective:
            # Pour les objectifs SMART, on cherche le JSON entier
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                response_text = json_match.group(0)
            
            try:
                data = json.loads(response_text)
                smart_objective = data.get("smart_objective", {})
                tasks = data.get("tasks", [])
                
                # G√©n√©rer des IDs uniques pour chaque t√¢che
                for i, task in enumerate(tasks):
                    task["completed"] = False
                    if "theme" not in task:
                        task["theme"] = theme
                    if "user_id" not in task:
                        task["user_id"] = "test_user"
                    # Supprimer l'ID pour laisser Supabase l'auto-g√©n√©rer
                    if "id" in task:
                        del task["id"]
                    logger.info(f"[GEN] T√¢che SMART √† ins√©rer: {task}")
                
                # Sauvegarder l'objectif SMART et ses t√¢ches
                await supabase_service.save_smart_objective(theme, smart_objective, tasks)
                logger.info(f"[GEN] T√¢ches SMART ins√©r√©es dans Supabase")
                
                return {
                    "theme": theme,
                    "smart_objective": smart_objective,
                    "tasks": tasks
                }
            except json.JSONDecodeError as e:
                logger.error(f"Erreur lors du parsing JSON: {str(e)}")
                raise HTTPException(status_code=500, detail="Erreur lors de la g√©n√©ration de l'objectif SMART")
        else:
            # Pour les t√¢ches normales
            try:
                # Nettoyer la r√©ponse pour s'assurer qu'il n'y a que du JSON
                json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                if json_match:
                    response_text = json_match.group(0)
                
                task_data = json.loads(response_text)
                task_data["completed"] = False
                if "theme" not in task_data:
                    task_data["theme"] = theme
                if "user_id" not in task_data:
                    task_data["user_id"] = "test_user"
                # Supprimer l'ID pour laisser Supabase l'auto-g√©n√©rer
                if "id" in task_data:
                    del task_data["id"]
                logger.info(f"[GEN] T√¢che simple √† ins√©rer: {task_data}")
                
                # Sauvegarder la t√¢che
                result = await supabase_service.create_task(task_data)
                logger.info(f"[GEN] R√©sultat insertion Supabase: {result}")
                
                return {"theme": theme, "tasks": [task_data]}
            except json.JSONDecodeError as e:
                logger.error(f"Erreur lors du parsing JSON: {str(e)}")
                raise HTTPException(status_code=500, detail="Erreur lors de la g√©n√©ration de la t√¢che")
                
    except Exception as e:
        logger.error(f"Erreur lors de la g√©n√©ration des t√¢ches: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur interne: {str(e)}")

# API pour r√©cup√©rer les t√¢ches par th√®me
@router.get("/tasks/by-theme/{theme}")
async def get_tasks(theme: str):
    try:
        tasks = await supabase_service.get_tasks_by_theme(theme)
        return {"theme": theme, "tasks": tasks}
    except Exception as e:
        logger.error(f"Erreur lors de la r√©cup√©ration des t√¢ches pour {theme}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur interne: {str(e)}")

# API pour mettre √† jour une t√¢che
@router.put("/tasks/{theme}/{task_id}")
async def update_task(theme: str, task_id: int, updates: Dict[str, Any] = Body(...)):
    try:
        updated_task = await supabase_service.update_task(theme, task_id, updates)
        if not updated_task:
            raise HTTPException(status_code=404, detail=f"T√¢che {task_id} non trouv√©e")
        return {"task": updated_task}
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur lors de la mise √† jour de la t√¢che {task_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur interne: {str(e)}")

# API pour supprimer une t√¢che
@router.delete("/tasks/{theme}/{task_id}")
async def delete_task(theme: str, task_id: int):
    try:
        success = await supabase_service.delete_task(theme, task_id)
        if not success:
            raise HTTPException(status_code=404, detail=f"T√¢che {task_id} non trouv√©e")
        return {"success": True}
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur lors de la suppression de la t√¢che {task_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur interne: {str(e)}")

# API pour obtenir des recommandations
@router.get("/recommendations")
async def get_recommendations(
    available_time: str = Query("30min", description="Temps disponible (e.g., 15min, 1h)"),
    energy_level: str = Query("medium", description="Niveau d'√©nergie (low, medium, high)")
):
    try:
        # Utiliser OpenAI pour g√©n√©rer des recommandations
        client = OpenAI(
            api_key=os.environ.get("OPENAI_API_KEY"),
        )
        
        # R√©cup√©rer toutes les t√¢ches
        all_themes = await supabase_service.get_all_themes()
        all_tasks = []
        
        for theme in all_themes:
            tasks = await supabase_service.get_tasks_by_theme(theme)
            # Ne r√©cup√©rer que les t√¢ches non compl√©t√©es
            incomplete_tasks = [t for t in tasks if not t.get("completed", False)]
            all_tasks.extend(incomplete_tasks)
        
        if not all_tasks:
            return {"message": "Aucune t√¢che disponible pour des recommandations", "recommendations": []}
        
        # Limiter le nombre de t√¢ches pour l'API
        if len(all_tasks) > 20:
            all_tasks = all_tasks[:20]
            
        # Envoyer les t√¢ches √† OpenAI pour obtenir des recommandations
        response = client.chat.completions.create(
            model=os.environ.get("MODEL_OPENAI", "gpt-3.5-turbo"),
            messages=[
                {"role": "system", "content": f"""Tu es un assistant intelligent qui aide √† prioriser les t√¢ches.
                
                L'utilisateur a {available_time} de disponible et son niveau d'√©nergie est {energy_level}.
                
                Voici ses t√¢ches en attente:
                {json.dumps(all_tasks, ensure_ascii=False, indent=2)}
                
                Recommande 1 √† 3 t√¢ches qui seraient les plus appropri√©es √† faire maintenant, en tenant compte:
                - Du temps disponible
                - Du niveau d'√©nergie actuel
                - De la priorit√© Eisenhower de chaque t√¢che
                - Des deadlines
                
                R√©ponds en fran√ßais et au format JSON avec:
                {{
                    "message": "Un message personnalis√© expliquant pourquoi ces t√¢ches sont recommand√©es",
                    "recommendations": [
                        {{
                            "task_id": "ID de la t√¢che recommand√©e",
                            "text": "Description de la t√¢che court max 3/4 mots",
                            "reason": "Explication courte de pourquoi cette t√¢che est recommand√©e maintenant"
                        }},
                        ...
                    ]
                }}
                """}
            ],
            temperature=0.7,
        )
        
        response_text = response.choices[0].message.content.strip()
        
        # Extraire le JSON
        json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
        if json_match:
            response_text = json_match.group(0)
            
        try:
            recommendations = json.loads(response_text)
            return recommendations
        except json.JSONDecodeError as e:
            logger.error(f"Erreur lors du parsing JSON des recommandations: {str(e)}")
            return {
                "message": "Voici quelques t√¢ches que vous pourriez faire maintenant",
                "recommendations": [
                    {
                        "task_id": task["id"],
                        "text": task["text"],
                        "reason": "Cette t√¢che correspond √† votre disponibilit√© actuelle"
                    }
                    for task in all_tasks[:3]
                ]
            }
            
    except Exception as e:
        logger.error(f"Erreur lors de la g√©n√©ration des recommandations: {str(e)}")
        return {
            "message": "Une erreur s'est produite lors de la g√©n√©ration des recommandations",
            "recommendations": []
        }

# API pour obtenir une revue hebdomadaire
@router.get("/weekly-review")
async def get_weekly_review():
    try:
        # Calculer les statistiques
        stats = await supabase_service.get_task_statistics()
        
        if not stats:
            return {
                "message": "Pas assez de donn√©es pour g√©n√©rer une revue hebdomadaire.",
                "statistics": {
                    "total_tasks": 0,
                    "completed_tasks": 0,
                    "pending_tasks": 0,
                    "completion_rate": 0,
                    "categories": {}
                },
                "smart_objectives": []
            }
        
        # R√©cup√©rer les objectifs SMART
        smart_objectives = await supabase_service.get_smart_objectives()
        
        # Utiliser OpenAI pour g√©n√©rer un r√©sum√©
        client = OpenAI(
            api_key=os.environ.get("OPENAI_API_KEY"),
        )
        
        response = client.chat.completions.create(
            model=os.environ.get("MODEL_OPENAI", "gpt-4o-mini"),
            messages=[
                {"role": "system", "content": f"""Tu es un coach en productivit√© qui analyse les donn√©es de t√¢ches d'un utilisateur.
                
                Voici les statistiques de l'utilisateur pour cette semaine:
                {json.dumps(stats, ensure_ascii=False, indent=2)}
                
                G√©n√®re une analyse personnalis√©e en fran√ßais avec:
                - Une √©valuation des performances de la semaine
                - Identification des points forts
                - Suggestion d'am√©lioration pour la semaine prochaine
                - Un ton encourageant et motivant
                
                R√©ponds en texte simple, sans formatage JSON.
                """}
            ],
            temperature=0.7,
        )
        
        message = response.choices[0].message.content.strip()
        
        return {
            "message": message,
            "statistics": stats,
            "smart_objectives": smart_objectives
        }
            
    except Exception as e:
        logger.error(f"Erreur lors de la g√©n√©ration de la revue hebdomadaire: {str(e)}")
        return {
            "message": "Une erreur s'est produite lors de la g√©n√©ration de la revue hebdomadaire.",
            "statistics": {
                "total_tasks": 0,
                "completed_tasks": 0,
                "pending_tasks": 0,
                "completion_rate": 0,
                "categories": {}
            },
            "smart_objectives": []
        }

# API simple pour marquer une t√¢che comme termin√©e
@router.patch("/tasks/{task_id}/complete")
async def mark_task_complete(task_id: int, body: Dict[str, Any] = Body(...)):
    logger.info(f"üîÑ === PATCH /api/tasks/{task_id}/complete ===")
    try:
        completed = body.get("completed", True)
        logger.info(f"üîÑ Marquage t√¢che {task_id} comme completed = {completed}")
        
        # Mise √† jour directe via Supabase
        updated_task = await supabase_service.update_task_by_id(task_id, {"completed": completed})
        
        if updated_task:
            logger.info(f"‚úÖ T√¢che {task_id} mise √† jour: completed = {updated_task.get('completed')}")
            return {"success": True, "task": updated_task}
        else:
            raise HTTPException(status_code=404, detail=f"T√¢che {task_id} non trouv√©e")
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur PATCH /api/tasks/{task_id}/complete: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur interne: {str(e)}")
